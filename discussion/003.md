<!-- Comment 003 - 2025-12-27T01:21:27+01:00 -->

## Prior Art Comparison: LLM Observability, Eval, and Agent Debugging

### Landscape Overview

The space has fragmented into several categories:

| Category | Examples | Focus |
|----------|----------|-------|
| **LLM Observability** | Langfuse, LangSmith, Helicone | Tracing, logging, cost tracking |
| **LLM Gateways** | Portkey, Helicone, LiteLLM | Routing, failover, rate limiting |
| **Eval Frameworks** | Promptfoo, Braintrust, RAGAS | Testing prompts, measuring quality |
| **Agent Debugging** | AgentOps, LangSmith, AgentPrism | Multi-step agent tracing |
| **Compliance/Audit** | (Gap) | Regulated industry requirements |

### Detailed Comparison

#### 1. LLM Observability Platforms

**Langfuse** (open source, MIT)
- Tracing, prompt management, evaluations
- Self-hostable, OpenTelemetry support
- SDK-based integration
- Free tier: 50k observations/month

**LangSmith** (LangChain)
- Deep LangChain/LangGraph integration
- Automatic tracing for LangChain apps
- Replay and compare runs
- Free tier: 5k traces/month, self-host enterprise only

**Helicone** (open source, MIT)
- Proxy-based (single URL change)
- Built-in caching (20-30% cost reduction)
- Distributed architecture (ClickHouse, Kafka)
- 50-80ms added latency
- Free tier: 50k logs/month

#### 2. LLM Gateways

**Portkey**
- Unified API for 1600+ models
- Smart routing (cost, performance, availability)
- Automatic failover
- Real-time observability dashboard
- Gartner Cool Vendor 2025
- Starts at $49/month

**LiteLLM** (open source)
- OpenAI-compatible API for 100+ providers
- Self-hostable
- More technical setup required

**TensorZero** (open source, Rust)
- Industrial-grade, low-latency
- Structured inferences, GitOps

#### 3. Eval Frameworks

**Promptfoo** (open source)
- CLI/YAML-based prompt testing
- A/B testing, red-teaming
- CI/CD integration
- Limited to basic metrics

**Braintrust**
- End-to-end platform (design → test → deploy)
- 9+ framework integrations
- Focus on eval workflows
- Weak on multi-step agent tracing

**RAGAS** (open source)
- RAG-specific evaluation
- Reference-free metrics
- Now supports agentic workflows
- Metrics can be opaque

#### 4. Agent Debugging

**AgentOps**
- Visual tracking of LLM calls, tools, multi-agent
- "Rewind and replay agent runs with point in time precision"
- 400+ LLM/framework support

**LangSmith**
- Step through agent decision path
- Prompt/template, context, tool selection, errors
- Replay and compare runs
- Best if using LangChain

**AgentPrism** (open source)
- React components for trace visualization
- OpenTelemetry-based
- Claims 80% reduction in debugging time

**Azure AI Foundry**
- Unified agent governance, eval, tracing, monitoring
- Adversarial scenario simulation
- Enterprise-focused

### Gap Analysis: Where TonyAPI Fits

| Capability | Existing Tools | TonyAPI Differentiator |
|------------|----------------|------------------------|
| **Tracing** | All have it | Structured diffs, not just logs |
| **Replay** | AgentOps, LangSmith | Branch and modify mid-conversation |
| **A/B Testing** | Promptfoo, Braintrust | Scopes: COW branches with full history |
| **Audit Trail** | Basic logging | Immutable diff chain, time-travel queries |
| **Multi-agent** | Limited | Shared state via logd, transaction coordination |
| **Compliance** | Gap in market | Built for fintech: tamper-evident, full reproducibility |
| **Integration** | SDK-heavy | Proxy-based: zero code change |
| **Data Model** | Opaque blobs | Structured, diffable, queryable (Tony format) |
| **Self-host** | Langfuse, Helicone | Open source core (tony-format) |

### Key Differentiators

#### 1. Structured Diffs vs Logs

Existing tools log events. TonyAPI stores structured diffs:

```
# Existing tools: append-only log
[2025-01-15 10:30:01] LLM call: model=claude-sonnet, tokens=150
[2025-01-15 10:30:02] Tool call: read_file(/src/main.go)
[2025-01-15 10:30:03] LLM response: "Here's the code..."

# TonyAPI: structured diff
conversations/conv-123/turns:
- !insert
    seq: 5
    request: {messages: [...]}
    response: {content: [...]}
    tools: [{id: toolu_01, name: read_file, ...}]
```

Benefits:
- Query any point in time: "what was the context at turn 5?"
- Diff between states: "what changed between turns 4 and 5?"
- Efficient storage: only changes stored, not full state

#### 2. Branching (Scopes) vs Replay

Existing replay: re-run from start, compare outputs

TonyAPI scopes: branch at any point, modify, continue

```
# Branch conversation at turn 5, change prompt
scope:experiment-v2/conversations/conv-123/meta:
  systemPrompt: !replace
    from: "You are a compliance checker..."
    to: "You are a senior compliance analyst..."

# Continue from turn 5 with new prompt
# Original conversation unchanged
```

Benefits:
- True A/B testing mid-conversation
- Test prompt changes without re-running
- Compare branches with structured diff

#### 3. Compliance-First Architecture

Existing tools: observability first, compliance bolted on

TonyAPI: audit trail is the core data model

| Requirement | Existing | TonyAPI |
|-------------|----------|---------|
| Immutable history | Varies | Append-only diff log |
| Tamper-evident | No | Hash chain possible |
| Point-in-time queries | Limited | Native (commit-based) |
| Reproducibility | Replay only | Exact state reconstruction |
| Data retention | Config | Native history |

Fintech regulators want:
- "Show me exactly what the agent saw and did on Jan 15 at 10:30"
- "Prove this hasn't been modified since"
- "Explain why it made this decision"

TonyAPI answers all three structurally, not through log archaeology.

#### 4. Proxy + Controllers Architecture

Existing proxies: capture traffic, store in their format

TonyAPI: proxies are controllers in a larger system

```
# Helicone/Portkey: standalone proxy
Agent → Proxy → LLM
           ↓
        Their DB (opaque)

# TonyAPI: proxy is a controller
Agent → LLM Proxy Controller → LLM
               ↓
             docd ← other controllers (Agent, Experiment, Replay)
               ↓
             logd (structured, diffable, branchable)
```

Benefits:
- Unified query across all data (MATCH any path)
- Transactions across concerns (atomic agent config + conversation update)
- Extensible (add new controllers without changing core)

### Competitive Positioning

**vs Langfuse/Helicone** (observability)
- They log, we diff
- They observe, we enable experimentation
- Similar: proxy-based, open source core

**vs LangSmith** (LangChain ecosystem)
- They're LangChain-native, we're framework-agnostic
- They replay, we branch
- Similar: agent debugging focus

**vs Braintrust/Promptfoo** (eval)
- They test prompts, we test full agent runs
- They're point-in-time, we're continuous history
- Similar: A/B testing goal

**vs AgentOps** (agent debugging)
- They visualize, we diff and branch
- Similar: replay capability

**vs Portkey** (gateway)
- They route and observe, we also store structured history
- They're gateway-first, we're state-first
- Similar: proxy approach

### Market Opportunity

The compliance gap is real:

> "Most companies lack fundamental capabilities that auditors expect to see. They have no audit trails, no proper access controls, no monitoring for AI-specific threats."

> "Financial institutions deploying AI without audit infrastructure face compounding risks: regulatory fines (averaging $5–10M for AI governance failures in 2024–2025)"

No existing tool is built compliance-first for fintech. They're all observability tools being stretched for compliance.

TonyAPI's structured diff model makes compliance a feature of the architecture, not a reporting layer on top.

### Risks

1. **"Good enough" observability** - Langfuse/Helicone may be sufficient for most
2. **Framework lock-in** - LangSmith wins if LangChain dominates
3. **Gateway consolidation** - Portkey adding more features
4. **Build complexity** - Controllers architecture is ambitious

### Mitigation

1. Focus on fintech (compliance is must-have, not nice-to-have)
2. Proxy approach = framework-agnostic
3. Open source core differentiates from Portkey
4. Phase implementation (proxies first, controllers later)

### Sources

- [Helicone: Complete Guide to LLM Observability](https://www.helicone.ai/blog/the-complete-guide-to-LLM-observability-platforms)
- [Langfuse: Best Helicone Alternative](https://langfuse.com/faq/all/best-helicone-alternative)
- [Braintrust: Best LLM Evaluation Tools](https://www.braintrust.dev/articles/best-llm-evaluation-tools-integrations-2025)
- [Portkey: LLM Proxy vs AI Gateway](https://portkey.ai/blog/llm-proxy-vs-ai-gateway/)
- [AgentOps](https://www.agentops.ai/)
- [Maxim: Agent Tracing for Debugging](https://www.getmaxim.ai/articles/agent-tracing-for-debugging-multi-agent-ai-systems/)
- [AI Audit Trail for Compliance](https://medium.com/@kuldeep.paul08/the-ai-audit-trail-how-to-ensure-compliance-and-transparency-with-llm-observability-74fd5f1968ef)
- [Audit Trails for Financial Services](https://lawrence-emenike.medium.com/audit-trails-and-explainability-for-compliance-building-the-transparency-layer-financial-services-d24961bad987)
- [AI Compliance Audits Mandatory 2025](https://www.ctrlaltnod.com/en/news/cybersecurity/companies-are-not-ready-for-llm-risk/)

